# Polygenic score and imputation accuracy from low-pass sequencing in diverse population

## Introduction

Genome-wide association studies (GWAS) and polygenic score (PGS) analyses typically rely on large-scale genetic data, which has traditionally been collected using SNP arrays and genotype imputation. However, low-pass whole-genome sequencing (lpWGS) is emerging as a promising alternative.

In this study, we compare the imputation accuracy and polygenic score performance of eight leading genotyping arrays and six lpWGS coverage levels (ranging from 0.5x to 2x) across diverse populations. Using data from 2,504 individuals in the 1000 Genomes Project, we apply a 10-fold cross-imputation approach to assess both imputation and PGS accuracy for four complex traits.

Our findings show that lpWGS performs on par with population-specific genotyping arrays in terms of both imputation accuracy and polygenic score estimation. Notably, lpWGS outperforms arrays in underrepresented populations and shows greater accuracy for rare and low-frequency variants.

These results highlight the potential of low-pass sequencing as a flexible, powerful alternative to genotyping arrays—particularly in studies involving genetically diverse or underrepresented populations.

## Analytical Pipeline Summary

![Overview](assets/img/Fig1.jpg)
<figcaption style="
    max-width: 100%; 
    margin: 0 auto; 
    font-size: 0.80em;
    text-align: justify;
  ">
    Figure 1: Overview of the analytical pipeline. A) 10-fold cross-imputation approach; (1) 10% of the samples are downsampled (BAM files) or filtered to retain only array variants (VCF files) to generate pseudo LPS and pseudo array data; (2) these data are imputed using the remaining 90% of the samples as the reference panel; (3) the imputed data from all batches are combined and then split by population; (4) performance is evaluated using high-coverage genotyping data as the ground truth. B) Data generation and imputation pipeline for LPS and SNP array data. 
</figcaption>

This study analyzes data from 2,504 unrelated individuals in the 1000 Genomes Project, re-sequenced at high coverage (30x) by the New York Genome Center (1KGPHC). Two main data sources are utilized:

- Mapped sequence data (CRAM format)
- Phased variant data (VCF format)

### 1. Variant Filtering
- VCF files are filtered to retain only bi-allelic SNPs with an allele count ≥ 2 to reduce noise in imputation and evaluation.

### 2. Data Simulation
- Low-pass sequencing (LPS): Simulated at six coverage levels (0.5x–2.0x) from mapped CRAM files, adjusting for a 9% duplication rate and incorporating realistic coverage variability.

- SNP Arrays: Eight genotyping arrays are simulated using known marker sets and harmonized to hg38. Pseudo-array data is generated by removing phasing information.

### 3. Cross-Validation Framework
- 10-fold cross-validation is used.
- Samples are stratified by superpopulation (EAS, EUR, SAS, AFR, AMR) to ensure balanced representation:
    - 4 batches of 251 samples
    - 6 batches of 250 samples
- In each fold:
    - 90% of data serves as the reference panel.
    - 10% of data serves as the target set for imputation.

### 4. Genotype Imputation
- SNP Arrays:
    - Phasing: `SHAPEIT5`
    - Imputation: `Minimac4`

- Low-Pass Sequencing:
    - Joint phasing and imputation: `GLIMPSE2`

### 5. Evaluation
- Imputed genotypes are merged by superpopulation.
- Performance is evaluated against 30x WGS data.